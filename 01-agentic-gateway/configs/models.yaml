models:
  small:
    name: Qwen/Qwen2.5-7B-Instruct
    max_model_len: 4096
    gpu_memory_utilization: 0.35
    quantization: null
    description: "Fast model for simple queries (Apache 2.0, ungated)"

  large:
    name: Qwen/Qwen2.5-32B-Instruct-AWQ
    max_model_len: 4096
    gpu_memory_utilization: 0.55
    quantization: awq
    description: "High-quality model for complex reasoning (AWQ INT4)"

# Cost estimates (per 1M tokens)
costs:
  small:
    input: 0.10
    output: 0.10
  large:
    input: 0.80
    output: 0.80
